# Introduction to the Lineage Project

Ever wondered **why** Artificial Intelligence evolved the way it did—not just _how_, but **what constraints forced each breakthrough?** The Lineage project is here to take you on a journey through the **causal chains** underlying AI's development, showing how:

- Hand-coded conditionals failed → Classical AI needed symbolic manipulation
- Symbol manipulation hit limits → Mathematics formalized state spaces
- Deterministic systems failed in real worlds → Statistics and probability entered
- Manual feature engineering became impossible → Neural networks learned representations
- Static models proved insufficient → Agents added continuous perception-action loops

This is not just a timeline. It's a **map of logical necessity**—understanding not just what happened, but why each stage _had_ to happen next given the problems and knowledge available.

## About Me

- I am Abdulhakeem Muhammed, the creator of the Lineage project. I started out as a Software Engineer with a passion for understanding and building systems that help solve real-world problems. Over time, my interest gravitated towards Artificial Intelligence, leading me to explore its vast landscape and the myriad of ideas that have shaped its evolution.
- My first encounter with AI was through basic machine learning algorithms and simple neural networks. But as someone who loves 'understanding the foundations' of knowledge, I found myself unable to fully appreciate the field without a deeper grasp of its history and the key concepts that have driven its progress. Why use 'this' model over 'that' one? What led to the development of certain architectures? What is the underlying algorithmic thinking behind these models?
- Again, I got involved with Data Engineering, Data Science, and AI Research. I was fortunate to work on various projects that allowed me to apply AI techniques in practical scenarios, including robotics, natural language processing, and computer vision. I researched and built an heuristic algorithms for solving optimization problems, which further fueled my curiosity about the theoretical underpinnings of AI.
- Afterwards, I found myself in the world of Generative AI, Large Language Models (LLMs), and Retrieval-Augmented Generation (RAG). However, I realized that many practitioners, including myself, often treated these models as black boxes without fully understanding their lineage and the foundational principles that underpin them.
- Lastly, I entered the world of Agentic AI using several frameworks and tools - and Model Context Protocol (MCP), to build autonomous agents capable of performing complex tasks. This experience further highlighted the importance of understanding the historical context and evolution of AI to effectively leverage its capabilities.

## The Challenge

- With every new knowledge or field, I realized there's a growing disconnection between all of these fields. As an ML student, I was taught that ML is a subset of AI. It is a common knowledge that AI has both ML and Statisctics as its subsets. But how do these fields overlap? In what ways do they contribute to the overall development of AI? How do they differ from each other? These questions led me to write the first piece of an attempt to clarify these relationships in a LinkedIn post titled "Demystifying AI, ML, and Statistics: Understanding Their Interconnections". I tried to explain the differences between ML algorithms and Statistical algorithms, highlighting their unique characteristics and applications.
- However, I soon realized that as I delved deeper into the world of AI, this 'disconnection' only grew wider. Especially in the new and emerging fields of LLMs, RAG, and Agentic AI, where many concepts and techniques seemed to be presented as isolated breakthroughs, without explaining:
  - **Why** they were necessary (what problems did they solve?)
  - **How** they built on earlier foundations (what prerequisites existed?)
  - **What** they made possible next (what new capabilities emerged?)
  - **Where** their core concepts originated (often going back decades or centuries)
    Without understanding this **causal lineage**, practitioners treat modern systems as black boxes. With it, every complex system becomes comprehensible as a logical response to earlier limitations.
- This lack of explicit causal lineage made it challenging to fully grasp _why_ certain systems were designed this way, and to predict what innovations might come next based on current bottlenecks.
- This also led to the notion that the field of Artificial Intelligence, especially the emerging technologies around LLMs, RAG, and Agentic AI, is only for some 'selected chosen ones'. Advancements and breakthroughs are often presented as sudden leaps into the unknown, rather than as part of a continuous evolution of ideas and innovations. This perception can create barriers to entry for those who are interested in learning about AI but feel intimidated by its complexity and perceived exclusivity.
- Many Agentic AI or GenAI developers might not be grounded in the foundational fields of AI such as Classical AI, Statistics, Machine Learning, and Neural Networks. This lack of grounding can lead to a superficial understanding of the technologies they are working with, potentially resulting in suboptimal designs and implementations.
- Again, many upskilling and design patterns for building advanced AI system are now only being shared and directed by the 'selected few'. This I believe will not only create a 'diverse sets of standards' and monopoly of knowledge but will also stifle innovation and creativity in the field. AI is a field that thrives on collaboration and the exchange of ideas, and restricting access to advanced knowledge and techniques goes against the very spirit of scientific inquiry and progress.
- Most importantly, I felt that some foundational fields of AI (including Mathematicians, Statisticians, and Classical AI researchers) were being 'left out' of the conversation around the latest advancements in AI. Their contributions and insights are crucial for understanding the full scope of AI's evolution and for ensuring that new developments are built on a solid foundation of knowledge and expertise.

## Looking Forward

- To address these challenges, I embarked on the Lineage project with the goal of creating a comprehensive and structured reconstruction that **explicitly maps the causal dependencies** driving AI's evolution. Not just _what happened when_, but **why each breakthrough was necessary and what it made possible**.
- We want to build a 'support' for the human and business needs, NOT A REPLACEMENT.
- AI should be seen not as a sudden leap into the unknown, but as a **logical evolution**—each stage solving problems identified in the previous stage, each building on mathematical and engineering insights that had to exist first. This way practitioners understand not just _how_ systems work, but _why_ they were designed this way.
- By documenting these causal chains, the Lineage project aims to foster a deeper understanding of why AI's current architecture is inevitable, and how researchers can identify the next bottleneck to solve.

## Conclusion

- Through the Lineage project, I hope to bridge the gap between foundational fields and emerging technologies by making their **causal relationships explicit**. Instead of treating Classical AI, Statistics, Machine Learning, and Neural Networks as disconnected chapters, this project shows:
  - How each emerged to solve problems in the previous
  - Why certain mathematical concepts were prerequisites
  - What each breakthrough made newly possible
  - How core abstractions (like the Environment-Agent loop) remained essential across all stages
- By providing a structured map of **causal dependencies and influence chains**, I aim to empower researchers, practitioners, and enthusiasts to understand why modern AI systems are designed as they are, identify the next innovation by recognizing current constraints, and build on proven principles rather than discovering independently.
- Ultimately, I believe that understanding AI's **causal lineage**—not just its history—is essential for both using AI effectively today and advancing it responsibly tomorrow. It transforms AI from a mysterious field into a comprehensible evolution of solutions to real problems.

# Thank You!

Abdulhakeem Ibiyemi, Muhammed
(January 30, 2026)
